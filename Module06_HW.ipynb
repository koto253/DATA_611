{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koto253/MATH_611/blob/main/Module06_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXsdbjCSpMUc"
      },
      "source": [
        "## Homework Week 6\n",
        "\n",
        "\n",
        "\n",
        "1. Explain the idea and calculation steps of PCA.\n",
        "2. Given the following data set, how many percent of the total variance can be explained by the top 2 principal components?\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import make_blobs\n",
        "from pandas import DataFrame\n",
        "# generate a classification dataset\n",
        "X, y = make_blobs(n_samples=1000, centers=3, n_features=10, random_state=1, cluster_std=3)\n",
        "```\n",
        "\n",
        "3. What is the most significant difference between PCA and LDA?\n",
        "4. Based on the data set given above, split data into 80% training and 20% test with stratification, apply PCA to pick the top 2 components, apply a classification algorithm, print the number of misclassified samples in the test set.\n",
        "5. Apply LDA to the above problem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain the idea of PCA**\n",
        "PCA sttands for \"Principal Component Analysis\", it helps us identify the most important patterns and reduce the dimensionality of the data while retaining crucial information\n",
        "\n",
        "  **Steps of PCA**\n",
        "\n",
        "    1. Standardize the d-dimensional dataset: Adjust the data to have zero mean and unit variance.\n",
        "    2. Construct the covariance matrix: Calculate the relationships and variances among the variables.\n",
        "    3. Decompose the covariance matrix into its eigenvectors and eigenvalues: Find the directions and magnitudes of the main patterns in the data.\n",
        "    4. Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors: Determine the most significant patterns by organizing the eigenvalues.\n",
        "    5. Select k eigenvectors corresponding to the k largest eigenvalues: Choose the top k patterns that capture the most variation in the data.\n",
        "    6. Construct a projection matrix W from the \"top\" k eigenvectors: Create a matrix that defines the transformation to the new feature subspace.\n",
        "    7. Transform the d-dimensional input dataset X using the projection matrix W: Map the original data to the lower-dimensional subspace defined by the selected eigenvectors.\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LZuyzOp0RWOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from pandas import DataFrame\n",
        "# generate a classification dataset\n",
        "X, y = make_blobs(n_samples=1000, centers=3, n_features=10, random_state=1, cluster_std=3)"
      ],
      "metadata": {
        "id": "N4AKY2l3anW_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA()\n",
        "\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "9r7NMb-BaoaZ",
        "outputId": "8bbdf067-c375-4fcb-a72c-9d2559305734"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pca.explained_variance_"
      ],
      "metadata": {
        "id": "0Kw4Bb13bSYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Variance explained by top 2 comp.: ', pca.explained_variance_ratio_[:2].sum())"
      ],
      "metadata": {
        "id": "SEphU_ZUa6UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. how many percent of the total variance can be explained by the top 2 principal components?\n",
        "\n",
        "`Variance explained by top 2 comp.:  0.7626066584852215` is `76.26%`"
      ],
      "metadata": {
        "id": "7rNFSVH6VzQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the most significant difference between PCA(Principal Component Analysis) and LDA(Linear Discriminant Analysis)?\n",
        "* PCA helps us understand the overall patterns in the data, like common trends/relationships among variables.\n",
        "* LDA helps us find features that can distinguish different groups or classes."
      ],
      "metadata": {
        "id": "3RMV76-vWsiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Based on the data set given above, split data into 80% training and 20% test with stratification, apply PCA to pick the top 2 components, apply a classification algorithm, print the number of misclassified samples in the test set**"
      ],
      "metadata": {
        "id": "_Ekg7B7Yds6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
        "\n",
        "# Applying PCA to select the top two components\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Applying a classification algorithm (e.g., Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "pca_pred = classifier.predict(X_test_pca)\n",
        "\n",
        "# Calculating the number of misclassified samples in the test set\n",
        "misclassified_samples = sum(y_test != pca_pred)\n",
        "print(\"Number of misclassified samples in the test set:\", misclassified_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEs00Pe2aIja",
        "outputId": "5339e218-40d4-4ccb-be01-af37af3da796"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified samples in the test set: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Apply LDA to the above problem**."
      ],
      "metadata": {
        "id": "qGYISL0fdyNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# Applying LDA to select the top two discriminative components\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "\n",
        "# Applying a classification algorithm (e.g., Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_lda, y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "lda_pred = classifier.predict(X_test_lda)\n",
        "\n",
        "# Calculating the number of misclassified samples in the test set\n",
        "misclassified_samples = sum(y_test != lda_pred)\n",
        "print(\"Number of misclassified samples in the test set:\", misclassified_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA4hwsCzbcEt",
        "outputId": "45158579-3a98-474c-e4c0-311dc5fded36"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified samples in the test set: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eMdPA6P7alV1"
      }
    }
  ]
}