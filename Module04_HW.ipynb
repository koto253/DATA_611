{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koto253/MATH_611/blob/main/Module04_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtTxMnv6oC36"
      },
      "source": [
        "## Homework Week 4\n",
        "\n",
        "1. Summarize the basic idea of logistic regression, support vector machines (SVM), and decision tree.\n",
        "1. Read the section of Random Forest, and summarize the major steps.\n",
        "1. Why do we split samples into training and test set? What does the stratify mean?\n",
        "1. Explain what are the bias-variance trade off and regularization.\n",
        "1. When do we use SVM's kernel method?\n",
        "1. Load the scikit-learn's Wine recognition dataset; separate 20% data as test data set; predict the wine quality using the 3 methods (logistic regression, support vector machines, decision tree), and print the accuracy in the test set of each method.\n",
        "\n",
        "\n",
        "To load the data set:\n",
        "```python\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "\n",
        "df = datasets.load_wine()\n",
        "\n",
        "X = df.data\n",
        "y = df.target\n",
        "\n",
        "```\n",
        "\n",
        "You can check the targets and features by:\n",
        "```python\n",
        "print(df.target_names)\n",
        "print(df.feature_names)\n",
        "```\n",
        "\n",
        "To get more details of the wine data set:https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJiDaX-dhJ3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Summarize the basic idea of logistic regression, support vector machines (SVM), and decision tree.**\n",
        "\n",
        "\n",
        "*   Logistic Regression\n",
        "     is a technique used to predict the outcome of something based on certain factors. Imagine you want to predict whether a student will pass or fail an exam based on their study time. Logistic regression helps us find the relationship between study time and the likelihood of passing or failing. It uses a mathematical formula to calculate the probability of an event happening. In this case, it calculates the probability of passing the exam based on the study time. It's like making an educated guess based on available data.\n",
        "\n",
        "--\n",
        "*   Support Vector Machines (SVM)\n",
        "    are like drawing a line to separate things. Imagine you have a group of red and blue balloons mixed together. SVM helps you find the best way to draw a line between the red and blue balloons so that they are well-separated. Once the line is drawn, you can easily tell if a new balloon should be red or blue by checking which side of the line it falls on. SVM helps you classify things based on their features.\n",
        "\n",
        "--\n",
        "*   Decision Trees\n",
        "    are like playing a guessing game. Let's say you want to figure out what animal someone is thinking of by asking a series of questions. Each question helps you narrow down the options until you can make a good guess. Decision trees work in a similar way. They ask questions about the characteristics of something and follow different paths until they reach a conclusion or a prediction. It helps you make decisions or predict outcomes by asking simple questions and getting closer to the answer step by step.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oK9ii2yLIrfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Read the section of Random Forest, and summarize the major steps**\n",
        "\n",
        "Random Forest is a machine learning algorithm that combines the predictions of many decision trees to make accurate predictions. It's used for things like identifying images, detecting spam emails, and predicting prices.\n",
        "How Random Forest works:\n",
        "\n",
        "*   First, we gather data with known labels. Then, we create a bunch of decision trees using different parts of the data and features.\n",
        "\n",
        "*   Each tree makes its own prediction.\n",
        "\n",
        "*   When we want to predict something new, we ask each tree for its prediction.\n",
        "\n",
        "*   And the final answer is the most common prediction from all the trees.\n",
        "Random Forest is good because it avoids overfitting and handles missing values.\n",
        "\n",
        "--\n",
        "\n",
        "***Note:*** Random Forest can be slower and more time-consuming compared to simpler algorithms due to the use of multiple decision trees.\n"
      ],
      "metadata": {
        "id": "CUpFgZEUKR7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Why do we split samples into training and test set?**\n",
        "\n",
        "We split samples into training and test sets to check how well a model can predict new information it hasn't seen before. The training set is like a practice set for the model to learn from, and the test set is like a quiz to see how well it learned. By using separate sets, we can see if the model is good at guessing on new things or if it only remembers what it practiced.\n",
        "\n",
        "In another words, We split the samples into training and test sets to ensure an unbiased evaluation of the model's performance on unseen data, which helps us assess its ability to generalize and make accurate predictions.\n",
        "\n",
        "\n",
        " **What does the stratify mean?**\n",
        "\"Stratify means \" ensuring that our machine learning models are trained and evaluated on a representative sample of data. It helps prevent bias and ensures that our models can accurately handle different categories or types of data. By maintaining the same proportion of categories in each subset, we can get a better understanding of how well our models perform across the entire dataset, particularly when dealing with imbalanced data where some categories may have fewer samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "YNpjcrkUKblo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Explain what are the bias-variance trade off and regularization.**\n",
        "\n",
        "\n",
        "\n",
        "*   The bias-variance trade-off refers to the relationship between a model's bias (simplification) and variance (flexibility). A model with high bias tends to oversimplify the data, leading to underfitting and poor predictive performance. On the other hand, a model with high variance tries to fit the training data too closely, resulting in overfitting and limited generalization to new data. The goal is to find an optimal trade-off between bias and variance that minimizes overall prediction error.\n",
        "\n",
        "--\n",
        "*   Regularization is like adding a rule to make sure our model doesn't get too complicated and focus on unnecessary details. It helps prevent the model from overfitting, which means memorizing specific examples too well but not understanding the bigger picture. By using regularization, we encourage the model to find simpler and more general patterns in the data, which makes it better at making predictions on new and unseen situations.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OWloz5KTKdFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. When do we use SVM's kernel method?**\n",
        "\n",
        "We use the kernel method in SVMs when the data is not easily separated by a straight line or plane. It helps us transform the data into a higher-dimensional space where we can draw a line or plane to separate different groups. This is useful for complex data that has complicated patterns. For example, it can help us recognize images, classify text, or find unusual things in data."
      ],
      "metadata": {
        "id": "UlXmHIHmKeig"
      }
    }
  ]
}